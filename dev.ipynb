{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'check_python_code': {'is_python_code': True}}\n",
      "{'evaluate_code': {'evaluation': {'difficulty': 'hard', 'explanation': 'The code snippet appears to be incomplete, as it only imports the os module without any further functionality. This lack of context makes it difficult to assess the maintainability and ease of modification of the code.'}}}\n",
      "{'unit_testing': {'unit_test_result': True}}\n",
      "null\n",
      "{'check_python_code': {'is_python_code': False}}\n",
      "{'evaluate_code': {'evaluation': {'difficulty': 'error', 'explanation': 'Failed to parse LLM output'}}}\n",
      "{'unit_testing': {'unit_test_result': False}}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph, END\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "import json\n",
    "import ast\n",
    "\n",
    "load_dotenv(\"env\")\n",
    "set_llm_cache(SQLiteCache(database_path=\".cache_langchain.db\"))\n",
    "\n",
    "llm_name = \"llama-3.1-8b-instant\"\n",
    "llm_generator = ChatGroq(cache=True, temperature=0.0, model_name=llm_name)\n",
    "\n",
    "# State\n",
    "class State(TypedDict):\n",
    "    input: str\n",
    "    is_python_code: bool\n",
    "    evaluation: dict\n",
    "    unit_test_result: bool\n",
    "\n",
    "# Nodes\n",
    "def check_python_code(state: State) -> State:\n",
    "    try:\n",
    "        ast.parse(state[\"input\"])\n",
    "        return {\"is_python_code\": True}\n",
    "    except SyntaxError:\n",
    "        return {\"is_python_code\": False}\n",
    "\n",
    "def evaluate_code(state: State) -> State:\n",
    "    prompt = prompt_evaluate_code()\n",
    "    result = llm_generator.invoke(prompt.format(input=state[\"input\"]))\n",
    "    try:\n",
    "        evaluation = json.loads(result.content)\n",
    "        return {\"evaluation\": evaluation}\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"evaluation\": {\"difficulty\": \"error\", \"explanation\": \"Failed to parse LLM output\"}}\n",
    "\n",
    "def unit_testing(state: State) -> State:\n",
    "    expected_keys = [\"difficulty\", \"explanation\"]\n",
    "    difficulty_values = [\"easy\", \"medium\", \"hard\"]\n",
    "    \n",
    "    evaluation = state[\"evaluation\"]\n",
    "    \n",
    "    if all(key in evaluation for key in expected_keys) and evaluation[\"difficulty\"] in difficulty_values:\n",
    "        return {\"unit_test_result\": True}\n",
    "    else:\n",
    "        return {\"unit_test_result\": False}\n",
    "\n",
    "# Edges\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"check_python_code\", check_python_code)\n",
    "workflow.add_node(\"evaluate_code\", evaluate_code)\n",
    "workflow.add_node(\"unit_testing\", unit_testing)\n",
    "\n",
    "workflow.set_entry_point(\"check_python_code\")\n",
    "workflow.add_edge(\"check_python_code\", \"evaluate_code\")\n",
    "workflow.add_edge(\"evaluate_code\", \"unit_testing\")\n",
    "\n",
    "# Conditional edges\n",
    "def decide_next_step(state: State):\n",
    "    if not state.get(\"is_python_code\", True):\n",
    "        return END\n",
    "    if \"unit_test_result\" in state:\n",
    "        return END if state[\"unit_test_result\"] else \"evaluate_code\"\n",
    "    return \"evaluate_code\"\n",
    "\n",
    "workflow.add_conditional_edges(\"check_python_code\", decide_next_step)\n",
    "workflow.add_conditional_edges(\"unit_testing\", decide_next_step)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# Function that returns prompt\n",
    "def prompt_evaluate_code() -> ChatPromptTemplate:\n",
    "    system_prompt = \"\"\"\n",
    "    You are a highly capable language model specialized in evaluating Python code in terms of ease of modification and maintainability. Your task is to classify given Python code snippets as either \"easy\", \"medium\", or \"hard\" to update, based on the complexity, structure, and best practices present in the code. Please follow the rules below:\n",
    "    - The input will always be a Python code snippet.\n",
    "    - The output must be a JSON object containing a \"difficulty\" value and an \"explanation\".\n",
    "    - The difficulty can be \"easy\", \"medium\", or \"hard\".\n",
    "    - The explanation must provide the reasoning behind your classification in terms of maintainability and ease of modification.\n",
    "    - The output format must be as follows:\n",
    "    ```\n",
    "    {{\n",
    "      \"difficulty\": \"[easy|medium|hard]\",\n",
    "      \"explanation\": \"[Put the explanation here]\"\n",
    "    }}\n",
    "    ```\n",
    "    ### Criteria for Classification:\n",
    "    1. **Easy**: The code follows good practices, has modular functions, meaningful variable names, and is overall simple to understand and modify.\n",
    "    2. **Medium**: The code may have some issues, such as lacking comments or using slightly unclear variable names, making it somewhat challenging to modify. It may also use complex logic that can be understood with effort.\n",
    "    3. **Hard**: The code has poor practices such as deeply nested loops, poorly named variables, lack of modularity, or complex interdependencies, making it difficult to modify.\n",
    "\n",
    "    Only output the json. No explanations.\n",
    "    \"\"\"\n",
    "\n",
    "    example_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"ai\", \"{output}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    examples = [\n",
    "        {\n",
    "            \"input\": \"\"\"\n",
    "def calculate_sum(numbers):\n",
    "    \"Calculate the sum of a list of numbers.\"\n",
    "    return sum(numbers)\n",
    "print(calculate_sum([1, 2, 3, 4, 5]))\n",
    "\"\"\",\n",
    "            \"output\": \"\"\"\n",
    "{{\n",
    "  \"difficulty\": \"easy\",\n",
    "  \"explanation\": \"The code is simple and modular, with a well-named function and parameter. It follows good practices, such as documentation and minimal complexity.\"\n",
    "}}\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"\"\"\n",
    "def process_data(data):\n",
    "    result = []\n",
    "    for d in data:\n",
    "        if d % 2 == 0:\n",
    "            result.append(d * 2)\n",
    "    return result\n",
    "print(process_data([1, 2, 3, 4, 5]))\n",
    "\"\"\",\n",
    "            \"output\": \"\"\"\n",
    "{{\n",
    "  \"difficulty\": \"medium\",\n",
    "  \"explanation\": \"The code lacks comments, and the purpose of processing is not immediately clear. Variable names are generic, and the loop has conditional logic that requires some thought to understand.\"\n",
    "}}\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"\"\"\n",
    "def func(a, b):\n",
    "    r = []\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(b)):\n",
    "            if a[i] == b[j]:\n",
    "                r.append((i, j))\n",
    "                for k in range(5):\n",
    "                    r.append(k * (i + j))\n",
    "    return r\n",
    "print(func([1, 2, 3], [3, 2, 1]))\n",
    "\"\"\",\n",
    "            \"output\": \"\"\"\n",
    "{{\n",
    "  \"difficulty\": \"hard\",\n",
    "  \"explanation\": \"The code has nested loops with poor variable naming, making it difficult to understand and maintain. Additionally, there is a deeply nested inner loop with unclear logic, leading to high cognitive load and making the code challenging to update.\"\n",
    "}}\n",
    "\"\"\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "        example_prompt=example_prompt,\n",
    "        examples=examples,\n",
    "    )\n",
    "\n",
    "    final_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            few_shot_prompt,\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    return final_prompt\n",
    "\n",
    "# Execution\n",
    "def evaluate_code_maintainability(code: str):\n",
    "    initial_state = {\"input\": code}\n",
    "    for output in app.stream(initial_state):\n",
    "        print(output)\n",
    "        if END in output:\n",
    "            if not output[END].get(\"is_python_code\", True):\n",
    "                return \"No Python code. Try again.\"\n",
    "            return output[END].get(\"evaluation\", \"Failed to evaluate code.\")\n",
    "\n",
    "# Example usage\n",
    "code_snippet = \"\"\"\n",
    "import os\n",
    "\"\"\"\n",
    "\n",
    "result = evaluate_code_maintainability(code_snippet)\n",
    "print(json.dumps(result, indent=2))\n",
    "\n",
    "# Test with non-Python input\n",
    "non_python_input = \"This is not Python code.\"\n",
    "result = evaluate_code_maintainability(non_python_input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage\n",
    "from typing_extensions import TypedDict\n",
    " \n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    " \n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    " \n",
    "graph_builder = StateGraph(State)\n",
    " \n",
    "load_dotenv(\"env\")\n",
    "# set_llm_cache(SQLiteCache(database_path=\".cache_langchain.db\"))\n",
    "\n",
    "llm_name = \"llama-3.1-8b-instant\"\n",
    "llm_generator = ChatGroq(cache=False, temperature=0.0, model_name=llm_name)\n",
    "\n",
    " \n",
    "# The chatbot node function takes the current State as input and returns an updated messages list. This is the basic pattern for all LangGraph node functions.\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_generator.invoke(state[\"messages\"])]}\n",
    " \n",
    "# Add a \"chatbot\" node. Nodes represent units of work. They are typically regular python functions.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    " \n",
    "# Add an entry point. This tells our graph where to start its work each time we run it.\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    " \n",
    "# Set a finish point. This instructs the graph \"any time this node is run, you can exit.\"\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    " \n",
    "# To be able to run our graph, call \"compile()\" on the graph builder. This creates a \"CompiledGraph\" we can use invoke on our state.\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chatbot': {'messages': [AIMessage(content='I couldn\\'t find any information on \"Langfuse.\" It\\'s possible that it\\'s a lesser-known or obscure term, or it could be a misspelling or variation of a different term. If you could provide more context or clarify what you\\'re referring to, I\\'d be happy to try and help you further.', response_metadata={'token_usage': {'completion_time': 0.086666667, 'completion_tokens': 65, 'prompt_time': 0.009526751, 'prompt_tokens': 40, 'queue_time': 0.951697046, 'total_time': 0.096193418, 'total_tokens': 105}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'stop', 'logprobs': None}, id='run-c55f192a-269b-4ffa-8650-5c0c0db7f438-0', usage_metadata={'input_tokens': 40, 'output_tokens': 65, 'total_tokens': 105})]}}\n"
     ]
    }
   ],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    " \n",
    "# Initialize Langfuse CallbackHandler for Langchain (tracing)\n",
    "langfuse_handler = CallbackHandler()\n",
    " \n",
    "for s in graph.stream({\"messages\": [HumanMessage(content = \"What is Langfuse?\")]},\n",
    "                      config={\"callbacks\": [langfuse_handler]}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langfuse.callback.langchain.LangchainCallbackHandler at 0x7f469d6db0d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langfuse_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchTracesResponse(data=[TraceWithDetails(id='773784c8-2ee5-4056-9741-e8d93218ed44', timestamp=datetime.datetime(2024, 10, 8, 1, 25, 57, 569000, tzinfo=datetime.timezone.utc), name='LangGraph', input={'messages': [{'content': 'What is Langfuse?'}]}, output={'messages': [{'id': '9023e6e0-4d94-45ea-802e-9f47efd22df1', 'content': 'What is Langfuse?'}, {'id': 'run-c55f192a-269b-4ffa-8650-5c0c0db7f438-0', 'content': 'I couldn\\'t find any information on \"Langfuse.\" It\\'s possible that it\\'s a lesser-known or obscure term, or it could be a misspelling or variation of a different term. If you could provide more context or clarify what you\\'re referring to, I\\'d be happy to try and help you further.', 'tool_calls': [], 'usage_metadata': {'input_tokens': 40, 'total_tokens': 105, 'output_tokens': 65}, 'additional_kwargs': {}, 'response_metadata': {'logprobs': None, 'model_name': 'llama-3.1-8b-instant', 'token_usage': {'queue_time': 0.951697046, 'total_time': 0.096193418, 'prompt_time': 0.009526751, 'total_tokens': 105, 'prompt_tokens': 40, 'completion_time': 0.086666667, 'completion_tokens': 65}, 'finish_reason': 'stop', 'system_fingerprint': 'fp_9cb648b966'}, 'invalid_tool_calls': []}]}, session_id=None, release=None, version=None, user_id=None, metadata=None, tags=[], public=False, html_path='/project/cm1zneepa0006ejhbk3e1ocd4/traces/773784c8-2ee5-4056-9741-e8d93218ed44', latency=1.9350001811981201, total_cost=0.0, observations=['38a7cf2d-7095-4823-a9cd-98b3257a03a1', '5aa442ea-5898-4484-8089-e5df0abcdc55', 'c2e192fe-dda0-4403-948d-87a63780932c', 'd83b02bd-cb51-45bf-9a74-f293cc23c534', 'e2a30c16-d99e-456b-942b-e18fbbaa389b'], scores=[], updatedAt='2024-10-08T01:26:00.053Z', createdAt='2024-10-08T01:25:58.447Z', externalId=None, bookmarked=False, projectId='cm1zneepa0006ejhbk3e1ocd4')], meta=MetaResponse(page=1, limit=50, total_items=1, total_pages=1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langfuse import Langfuse\n",
    "langfuse = Langfuse()\n",
    "traces = langfuse.fetch_traces()\n",
    "traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '773784c8-2ee5-4056-9741-e8d93218ed44',\n",
       " 'timestamp': datetime.datetime(2024, 10, 8, 1, 25, 57, 569000, tzinfo=datetime.timezone.utc),\n",
       " 'name': 'LangGraph',\n",
       " 'input': {'messages': [{'content': 'What is Langfuse?'}]},\n",
       " 'output': {'messages': [{'id': '9023e6e0-4d94-45ea-802e-9f47efd22df1',\n",
       "    'content': 'What is Langfuse?'},\n",
       "   {'id': 'run-c55f192a-269b-4ffa-8650-5c0c0db7f438-0',\n",
       "    'content': 'I couldn\\'t find any information on \"Langfuse.\" It\\'s possible that it\\'s a lesser-known or obscure term, or it could be a misspelling or variation of a different term. If you could provide more context or clarify what you\\'re referring to, I\\'d be happy to try and help you further.',\n",
       "    'tool_calls': [],\n",
       "    'usage_metadata': {'input_tokens': 40,\n",
       "     'total_tokens': 105,\n",
       "     'output_tokens': 65},\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {'logprobs': None,\n",
       "     'model_name': 'llama-3.1-8b-instant',\n",
       "     'token_usage': {'queue_time': 0.951697046,\n",
       "      'total_time': 0.096193418,\n",
       "      'prompt_time': 0.009526751,\n",
       "      'total_tokens': 105,\n",
       "      'prompt_tokens': 40,\n",
       "      'completion_time': 0.086666667,\n",
       "      'completion_tokens': 65},\n",
       "     'finish_reason': 'stop',\n",
       "     'system_fingerprint': 'fp_9cb648b966'},\n",
       "    'invalid_tool_calls': []}]},\n",
       " 'tags': [],\n",
       " 'public': False,\n",
       " 'htmlPath': '/project/cm1zneepa0006ejhbk3e1ocd4/traces/773784c8-2ee5-4056-9741-e8d93218ed44',\n",
       " 'latency': 1.9350001811981201,\n",
       " 'totalCost': 0.0,\n",
       " 'observations': ['38a7cf2d-7095-4823-a9cd-98b3257a03a1',\n",
       "  '5aa442ea-5898-4484-8089-e5df0abcdc55',\n",
       "  'c2e192fe-dda0-4403-948d-87a63780932c',\n",
       "  'd83b02bd-cb51-45bf-9a74-f293cc23c534',\n",
       "  'e2a30c16-d99e-456b-942b-e18fbbaa389b'],\n",
       " 'scores': [],\n",
       " 'updatedAt': '2024-10-08T01:26:00.053Z',\n",
       " 'createdAt': '2024-10-08T01:25:58.447Z',\n",
       " 'bookmarked': False,\n",
       " 'projectId': 'cm1zneepa0006ejhbk3e1ocd4',\n",
       " 'sessionId': None,\n",
       " 'release': None,\n",
       " 'version': None,\n",
       " 'userId': None,\n",
       " 'metadata': None,\n",
       " 'externalId': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces.data[0].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchObservationsResponse(data=[ObservationsView(id='c2e192fe-dda0-4403-948d-87a63780932c', trace_id='773784c8-2ee5-4056-9741-e8d93218ed44', type='SPAN', name='ChannelWrite<chatbot,messages>', start_time=datetime.datetime(2024, 10, 8, 1, 25, 59, 500000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2024, 10, 8, 1, 25, 59, 502000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'messages': [{'id': 'run-c55f192a-269b-4ffa-8650-5c0c0db7f438-0', 'content': 'I couldn\\'t find any information on \"Langfuse.\" It\\'s possible that it\\'s a lesser-known or obscure term, or it could be a misspelling or variation of a different term. If you could provide more context or clarify what you\\'re referring to, I\\'d be happy to try and help you further.', 'tool_calls': [], 'usage_metadata': {'input_tokens': 40, 'total_tokens': 105, 'output_tokens': 65}, 'additional_kwargs': {}, 'response_metadata': {'logprobs': None, 'model_name': 'llama-3.1-8b-instant', 'token_usage': {'queue_time': 0.951697046, 'total_time': 0.096193418, 'prompt_time': 0.009526751, 'total_tokens': 105, 'prompt_tokens': 40, 'completion_time': 0.086666667, 'completion_tokens': 65}, 'finish_reason': 'stop', 'system_fingerprint': 'fp_9cb648b966'}, 'invalid_tool_calls': []}]}, version=None, metadata={'tags': ['seq:step:2', 'langsmith:hidden'], 'langgraph_node': 'chatbot', 'langgraph_step': 1, 'langgraph_task_idx': 0, 'langgraph_triggers': ['start:chatbot']}, output={'messages': [{'id': 'run-c55f192a-269b-4ffa-8650-5c0c0db7f438-0', 'content': 'I couldn\\'t find any information on \"Langfuse.\" It\\'s possible that it\\'s a lesser-known or obscure term, or it could be a misspelling or variation of a different term. If you could provide more context or clarify what you\\'re referring to, I\\'d be happy to try and help you further.', 'tool_calls': [], 'usage_metadata': {'input_tokens': 40, 'total_tokens': 105, 'output_tokens': 65}, 'additional_kwargs': {}, 'response_metadata': {'logprobs': None, 'model_name': 'llama-3.1-8b-instant', 'token_usage': {'queue_time': 0.951697046, 'total_time': 0.096193418, 'prompt_time': 0.009526751, 'total_tokens': 105, 'prompt_tokens': 40, 'completion_time': 0.086666667, 'completion_tokens': 65}, 'finish_reason': 'stop', 'system_fingerprint': 'fp_9cb648b966'}, 'invalid_tool_calls': []}]}, usage=Usage(input=0, output=0, total=0, unit=None, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id='38a7cf2d-7095-4823-a9cd-98b3257a03a1', prompt_id=None, prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=None, latency=0.002, time_to_first_token=None, unit=None, updatedAt='2024-10-08T01:26:00.063Z', projectId='cm1zneepa0006ejhbk3e1ocd4', promptTokens=0, createdAt='2024-10-08T01:26:00.046Z', completionTokens=0, totalTokens=0), ObservationsView(id='5aa442ea-5898-4484-8089-e5df0abcdc55', trace_id='773784c8-2ee5-4056-9741-e8d93218ed44', type='GENERATION', name='ChatGroq', start_time=datetime.datetime(2024, 10, 8, 1, 25, 57, 584000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2024, 10, 8, 1, 25, 59, 499000, tzinfo=datetime.timezone.utc), completion_start_time=None, model='llama-3.1-8b-instant', model_parameters={}, input=[{'role': 'user', 'content': 'What is Langfuse?'}], version=None, metadata={'tags': ['seq:step:1'], 'ls_provider': 'groq', 'ls_model_name': 'llama-3.1-8b-instant', 'ls_model_type': 'chat', 'langgraph_node': 'chatbot', 'langgraph_step': 1, 'ls_temperature': 1e-08, 'langgraph_task_idx': 0, 'langgraph_triggers': ['start:chatbot']}, output={'role': 'assistant', 'content': 'I couldn\\'t find any information on \"Langfuse.\" It\\'s possible that it\\'s a lesser-known or obscure term, or it could be a misspelling or variation of a different term. If you could provide more context or clarify what you\\'re referring to, I\\'d be happy to try and help you further.'}, usage=Usage(input=40, output=65, total=105, unit=None, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id='38a7cf2d-7095-4823-a9cd-98b3257a03a1', prompt_id=None, prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=None, latency=1.915, time_to_first_token=None, unit=None, updatedAt='2024-10-08T01:25:59.522Z', projectId='cm1zneepa0006ejhbk3e1ocd4', promptTokens=40, createdAt='2024-10-08T01:25:58.485Z', completionTokens=65, totalTokens=105), ObservationsView(id='38a7cf2d-7095-4823-a9cd-98b3257a03a1', trace_id='773784c8-2ee5-4056-9741-e8d93218ed44', type='SPAN', name='chatbot', start_time=datetime.datetime(2024, 10, 8, 1, 25, 57, 581000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2024, 10, 8, 1, 25, 59, 502000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'messages': [{'id': '9023e6e0-4d94-45ea-802e-9f47efd22df1', 'content': 'What is Langfuse?'}]}, version=None, metadata={'tags': ['graph:step:1'], 'langgraph_node': 'chatbot', 'langgraph_step': 1, 'langgraph_task_idx': 0, 'langgraph_triggers': ['start:chatbot']}, output={'messages': [{'id': 'run-c55f192a-269b-4ffa-8650-5c0c0db7f438-0', 'content': 'I couldn\\'t find any information on \"Langfuse.\" It\\'s possible that it\\'s a lesser-known or obscure term, or it could be a misspelling or variation of a different term. If you could provide more context or clarify what you\\'re referring to, I\\'d be happy to try and help you further.', 'tool_calls': [], 'usage_metadata': {'input_tokens': 40, 'total_tokens': 105, 'output_tokens': 65}, 'additional_kwargs': {}, 'response_metadata': {'logprobs': None, 'model_name': 'llama-3.1-8b-instant', 'token_usage': {'queue_time': 0.951697046, 'total_time': 0.096193418, 'prompt_time': 0.009526751, 'total_tokens': 105, 'prompt_tokens': 40, 'completion_time': 0.086666667, 'completion_tokens': 65}, 'finish_reason': 'stop', 'system_fingerprint': 'fp_9cb648b966'}, 'invalid_tool_calls': []}]}, usage=Usage(input=0, output=0, total=0, unit=None, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id='e2a30c16-d99e-456b-942b-e18fbbaa389b', prompt_id=None, prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=None, latency=1.921, time_to_first_token=None, unit=None, updatedAt='2024-10-08T01:26:00.072Z', projectId='cm1zneepa0006ejhbk3e1ocd4', promptTokens=0, createdAt='2024-10-08T01:25:58.474Z', completionTokens=0, totalTokens=0), ObservationsView(id='d83b02bd-cb51-45bf-9a74-f293cc23c534', trace_id='773784c8-2ee5-4056-9741-e8d93218ed44', type='SPAN', name='__start__', start_time=datetime.datetime(2024, 10, 8, 1, 25, 57, 572000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2024, 10, 8, 1, 25, 57, 574000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'messages': [{'content': 'What is Langfuse?'}]}, version=None, metadata={'tags': ['graph:step:0', 'langsmith:hidden'], 'langgraph_node': '__start__', 'langgraph_step': 0, 'langgraph_task_idx': 0, 'langgraph_triggers': ['__start__']}, output={'messages': [{'content': 'What is Langfuse?'}]}, usage=Usage(input=0, output=0, total=0, unit=None, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id='e2a30c16-d99e-456b-942b-e18fbbaa389b', prompt_id=None, prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=None, latency=0.002, time_to_first_token=None, unit=None, updatedAt='2024-10-08T01:25:58.495Z', projectId='cm1zneepa0006ejhbk3e1ocd4', promptTokens=0, createdAt='2024-10-08T01:25:58.465Z', completionTokens=0, totalTokens=0), ObservationsView(id='e2a30c16-d99e-456b-942b-e18fbbaa389b', trace_id='773784c8-2ee5-4056-9741-e8d93218ed44', type='SPAN', name='LangGraph', start_time=datetime.datetime(2024, 10, 8, 1, 25, 57, 570000, tzinfo=datetime.timezone.utc), end_time=datetime.datetime(2024, 10, 8, 1, 25, 59, 505000, tzinfo=datetime.timezone.utc), completion_start_time=None, model=None, model_parameters=None, input={'messages': [{'content': 'What is Langfuse?'}]}, version=None, metadata=None, output={'messages': [{'id': '9023e6e0-4d94-45ea-802e-9f47efd22df1', 'content': 'What is Langfuse?'}, {'id': 'run-c55f192a-269b-4ffa-8650-5c0c0db7f438-0', 'content': 'I couldn\\'t find any information on \"Langfuse.\" It\\'s possible that it\\'s a lesser-known or obscure term, or it could be a misspelling or variation of a different term. If you could provide more context or clarify what you\\'re referring to, I\\'d be happy to try and help you further.', 'tool_calls': [], 'usage_metadata': {'input_tokens': 40, 'total_tokens': 105, 'output_tokens': 65}, 'additional_kwargs': {}, 'response_metadata': {'logprobs': None, 'model_name': 'llama-3.1-8b-instant', 'token_usage': {'queue_time': 0.951697046, 'total_time': 0.096193418, 'prompt_time': 0.009526751, 'total_tokens': 105, 'prompt_tokens': 40, 'completion_time': 0.086666667, 'completion_tokens': 65}, 'finish_reason': 'stop', 'system_fingerprint': 'fp_9cb648b966'}, 'invalid_tool_calls': []}]}, usage=Usage(input=0, output=0, total=0, unit=None, input_cost=None, output_cost=None, total_cost=None), level=<ObservationLevel.DEFAULT: 'DEFAULT'>, status_message=None, parent_observation_id=None, prompt_id=None, prompt_name=None, prompt_version=None, model_id=None, input_price=None, output_price=None, total_price=None, calculated_input_cost=None, calculated_output_cost=None, calculated_total_cost=None, latency=1.935, time_to_first_token=None, unit=None, updatedAt='2024-10-08T01:26:00.081Z', projectId='cm1zneepa0006ejhbk3e1ocd4', promptTokens=0, createdAt='2024-10-08T01:25:58.457Z', completionTokens=0, totalTokens=0)], meta=MetaResponse(page=1, limit=50, total_items=5, total_pages=1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langfuse.fetch_observations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
